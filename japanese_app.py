import streamlit as st
import pandas as pd
import random
import asyncio
import edge_tts
from io import BytesIO
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
import pykakasi 
from datetime import datetime, timedelta
import re
import difflib
from streamlit_gsheets import GSheetsConnection

# --- è¨­å®šå€ ---
# ä¸å†éœ€è¦ DATA_FILENAME, MISTAKE_FILENAME ç­‰ï¼Œå…¨éƒ¨ç”± Google Sheets ç®¡ç†
TEMP_AUDIO_FILE = "temp_jp_voice.mp3"

# --- 1. Google Sheets æ ¸å¿ƒé€£ç·šèˆ‡è®€å¯« ---

def get_db_connection():
    return st.connection("gsheets", type=GSheetsConnection)

def load_data_from_sheet():
    conn = get_db_connection()
    try:
        # read(ttl=0) ç¢ºä¿æ¯æ¬¡éƒ½è®€å–æœ€æ–°è³‡æ–™ï¼Œä¸å¿«å–
        df = conn.read(ttl=0)
        
        # è£œé½Šå¿…è¦æ¬„ä½ï¼Œé˜²æ­¢æ–° Sheet ç¼ºå°‘æ¬„ä½å ±éŒ¯
        expected_cols = ["Sentence", "Translation", "Group", "Parsing", 
                         "Vocab List", "Meaning", "Time", "Weak", 
                         "Next_Review", "Interval", "Reps"]
        
        for col in expected_cols:
            if col not in df.columns:
                df[col] = None
        
        # è³‡æ–™æ¸…ç†
        df = df.fillna("")
        return df
    except Exception as e:
        st.error(f"Google Sheets é€£ç·šå¤±æ•—: {e}")
        return pd.DataFrame()

def save_data_to_sheet(df):
    conn = get_db_connection()
    try:
        conn.update(data=df)
    except Exception as e:
        st.error(f"å¯«å…¥ Google Sheets å¤±æ•—: {e}")

# --- 2. è³‡æ–™è§£æ (DataFrame -> App æ ¼å¼) ---

def parse_data(df):
    sentence_data = [] 
    vocab_data = []    
    group_map = {}     
    
    all_sentence_translations = []
    all_vocab_meanings = []
    
    srs_map = {} # ç”¨ä¾†å¿«é€ŸæŸ¥æ‰¾ SRS ç‹€æ…‹
    mistakes_list = [] # ç”¨ä¾†å¿«é€ŸæŸ¥æ‰¾éŒ¯é¡Œ

    default_date = datetime.now().strftime("%Y-%m-%d")

    for idx, row in df.iterrows():
        # --- é€šç”¨æ¬„ä½è™•ç† ---
        time_str = str(row.get('Time', default_date)).strip()
        if not time_str: time_str = default_date
        try:
             # å˜—è©¦æ­£è¦åŒ–æ—¥æœŸ
             time_str = pd.to_datetime(time_str).strftime("%Y-%m-%d")
        except: pass

        # --- SRS æ•¸æ“šè®€å– ---
        next_review = str(row.get('Next_Review', '')).strip()
        if not next_review: next_review = default_date # é è¨­ä»Šå¤©
        try:
            next_review = pd.to_datetime(next_review).strftime("%Y-%m-%d")
        except: next_review = default_date

        try:
            interval = int(float(row.get('Interval', 0) or 0))
            reps = int(float(row.get('Reps', 0) or 0))
        except:
            interval = 0
            reps = 0

        is_weak = str(row.get('Weak', '')).strip().lower() in ['yes', 'true', '1']

        # --- å¥å­è§£æ ---
        s_ja = str(row.get('Sentence', '')).strip()
        s_ch = str(row.get('Translation', '')).strip()
        gid  = str(row.get('Group', '')).strip()
        
        # Parsing è™•ç†
        parsing_raw = str(row.get('Parsing', '')).strip().replace('ï¼‹', '+')
        
        if s_ja:
            # å»ºç«‹å¥å­è³‡æ–™
            item = {
                "type": "sentence",
                "sentence": s_ja,
                "translation": s_ch,
                "group": gid,
                "parsing": [p.strip() for p in parsing_raw.split('+') if p.strip()],
                "start_date": time_str,
                "row_idx": idx # è¨˜ä½ Row Index ä»¥ä¾¿æ›´æ–°
            }
            sentence_data.append(item)
            all_sentence_translations.append(s_ch)
            
            if gid:
                if gid not in group_map: group_map[gid] = []
                if s_ja not in group_map[gid]: group_map[gid].append(s_ja)
            
            # å­˜å…¥ SRS Map (Key: Sentence)
            srs_map[s_ja] = {"next_review": next_review, "interval": interval, "reps": reps, "row_idx": idx}
            if is_weak: mistakes_list.append(s_ja)

        # --- å–®å­—è§£æ ---
        v_list_raw = str(row.get('Vocab List', '')).strip()
        m_list_raw = str(row.get('Meaning', '')).strip()
        
        if v_list_raw and m_list_raw:
            v_items = [x.strip() for x in v_list_raw.split('ã€‚') if x.strip()]
            m_items = [x.strip() for x in m_list_raw.split('ã€‚') if x.strip()]
            
            if len(v_items) == len(m_items):
                for i, v_str in enumerate(v_items):
                    if 'ï½œ' in v_str:
                        kanji, reading = v_str.split('ï½œ', 1)
                    else:
                        kanji, reading = v_str, v_str
                    
                    kanji = kanji.strip()
                    
                    # âš ï¸ æ³¨æ„ï¼šå–®å­—ç›®å‰å…±ç”¨åŒä¸€è¡Œçš„ SRS æ•¸æ“š
                    # è‹¥è¦ç²¾ç¢ºè¿½è¹¤æ¯å€‹å–®å­—ï¼ŒSheet çµæ§‹éœ€æ”¹è®Šã€‚ç›®å‰ç°¡åŒ–ç‚ºï¼šå–®å­—é¡Œæ›´æ–°æ•´è¡Œæ•¸æ“šã€‚
                    v_item = {
                        "type": "vocab",
                        "kanji": kanji,
                        "reading": reading.strip(),
                        "meaning": m_items[i],
                        "start_date": time_str,
                        "row_idx": idx 
                    }
                    vocab_data.append(v_item)
                    all_vocab_meanings.append(m_items[i])
                    
                    # å­˜å…¥ SRS Map (Key: Kanji)
                    # æ³¨æ„ï¼šå¦‚æœåŒä¸€è¡Œæœ‰å¤šå€‹å–®å­—ï¼ŒKey ä¸åŒä½† Row Index ç›¸åŒ
                    srs_map[kanji] = {"next_review": next_review, "interval": interval, "reps": reps, "row_idx": idx}
                    if is_weak: mistakes_list.append(kanji)

    return sentence_data, vocab_data, group_map, (all_sentence_translations, all_vocab_meanings), srs_map, mistakes_list

# --- 3. SRS æ›´æ–°é‚è¼¯ (å¯«å› DataFrame ä¸¦ä¸Šå‚³) ---

def update_srs_status_sheet(key, is_correct, row_idx):
    df = st.session_state.raw_df # å–å¾—ç›®å‰çš„ DataFrame
    today_str = datetime.now().strftime("%Y-%m-%d")
    
    # è®€å–ç•¶å‰æ•¸å€¼
    try:
        current_interval = int(float(df.at[row_idx, "Interval"] or 0))
        current_reps = int(float(df.at[row_idx, "Reps"] or 0))
    except:
        current_interval = 0
        current_reps = 0
    
    if is_correct:
        # ç­”å°ï¼šæ‹‰é•·é–“éš”
        if current_interval == 0: new_interval = 1
        elif current_interval == 1: new_interval = 3
        else: new_interval = int(current_interval * 2.2)
        new_reps = current_reps + 1
        is_weak = "No" # ç­”å°ç§»é™¤ Weak æ¨™è¨˜
    else:
        # ç­”éŒ¯ï¼šé‡ç½®
        new_interval = 0
        new_reps = 0
        is_weak = "Yes" # æ¨™è¨˜ç‚º Weak
        
    next_date = datetime.now() + timedelta(days=new_interval)
    new_next_review = next_date.strftime("%Y-%m-%d")
    
    # æ›´æ–° DataFrame
    df.at[row_idx, "Interval"] = new_interval
    df.at[row_idx, "Reps"] = new_reps
    df.at[row_idx, "Next_Review"] = new_next_review
    df.at[row_idx, "Weak"] = is_weak
    
    # å¯«å› Google Sheets
    # ç‚ºäº†æ•ˆèƒ½ï¼Œé€™è£¡æ¯æ¬¡ç­”é¡Œéƒ½å¯«å…¥ã€‚è‹¥è¦ºå¾—æ…¢ï¼Œå¯æ”¹ç‚ºåªæ›´æ–° session_state dfï¼Œå¦è¨­ä¸€é¡†æŒ‰éˆ•ã€Œå„²å­˜é€²åº¦ã€
    save_data_to_sheet(df)
    
    # æ›´æ–° Session State ä¸­çš„æš«å­˜ï¼Œä»¥å…é é¢æ²’é‡æ•´è®€åˆ°èˆŠè³‡æ–™
    st.session_state.raw_df = df
    # åŒæ­¥æ›´æ–° srs_map
    if key in st.session_state.srs_map:
        st.session_state.srs_map[key] = {
            "next_review": new_next_review,
            "interval": new_interval,
            "reps": new_reps,
            "row_idx": row_idx
        }
    
    # åŒæ­¥æ›´æ–° mistakes_list
    if is_correct:
        if key in st.session_state.mistakes_list:
            st.session_state.mistakes_list.remove(key)
    else:
        if key not in st.session_state.mistakes_list:
            st.session_state.mistakes_list.append(key)
            
    return new_interval, new_next_review

# --- 4. è¼”åŠ©å·¥å…· (TTS, Diff, Kakasi) ---

async def _edge_tts_save(text, voice="ja-JP-KeitaNeural"):
    try:
        communicate = edge_tts.Communicate(text, voice)
        await communicate.save(TEMP_AUDIO_FILE)
        return True
    except Exception as e: return False

def get_audio_bytes(text):
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        success = loop.run_until_complete(_edge_tts_save(text))
        if success:
            with open(TEMP_AUDIO_FILE, "rb") as f: return f.read()
    except: pass
    return None

def get_hiragana(text):
    kks = pykakasi.kakasi()
    result = kks.convert(text)
    return "".join([item['hira'] for item in result])

def generate_diff(user_text, target_text):
    s = difflib.SequenceMatcher(None, user_text, target_text)
    html = []
    for opcode, a0, a1, b0, b1 in s.get_opcodes():
        if opcode == 'equal': html.append(f"<span style='color:green; font-weight:bold'>{target_text[b0:b1]}</span>")
        elif opcode == 'insert': html.append(f"<span style='color:red; text-decoration:underline; background-color:#ffe6e6'>[{target_text[b0:b1]}]</span>")
        elif opcode == 'delete': html.append(f"<span style='color:gray; text-decoration:line-through'>{user_text[a0:a1]}</span>")
        elif opcode == 'replace':
            html.append(f"<span style='color:gray; text-decoration:line-through'>{user_text[a0:a1]}</span>")
            html.append(f"<span style='color:red; background-color:#ffe6e6'>[{target_text[b0:b1]}]</span>")
    return "".join(html)

def transcribe_audio_bytes(audio_bytes):
    r = sr.Recognizer()
    try:
        with sr.AudioFile(BytesIO(audio_bytes)) as source:
            audio_data = r.record(source)
            return r.recognize_google(audio_data, language='ja-JP')
    except: return "Not Recognized"

# --- 5. åˆå§‹åŒ–èˆ‡ç‹€æ…‹ç®¡ç† ---

if 'initialized' not in st.session_state:
    with st.spinner("æ­£åœ¨é€£ç·šè‡³ Google Sheets..."):
        df = load_data_from_sheet()
        st.session_state.raw_df = df # ä¿ç•™åŸå§‹ DF ä»¥ä¾¿å¯«å›
        
        s_data, v_data, g_map, pools, srs_map, m_list = parse_data(df)
        
        st.session_state.sentence_data = s_data
        st.session_state.vocab_data = v_data
        st.session_state.group_map = g_map
        st.session_state.trans_pool = pools[0]
        st.session_state.meaning_pool = pools[1]
        
        st.session_state.srs_map = srs_map
        st.session_state.mistakes_list = m_list
        
        st.session_state.current_q = None
        st.session_state.mode = None
        st.session_state.feedback = None
        st.session_state.audio_data = None
        st.session_state.user_audio_bytes = None
        st.session_state.options = []
        st.session_state.shuffled_parsing = []
        st.session_state.selected_indices = []
        
        st.session_state.initialized = True

# --- 6. æ ¸å¿ƒé¸é¡Œé‚è¼¯ ---

def pick_new_question():
    st.session_state.selected_indices = [] 
    st.session_state.shuffled_parsing = []
    st.session_state.feedback = None
    st.session_state.user_audio_bytes = None

    today_str = datetime.now().strftime("%Y-%m-%d")
    srs_map = st.session_state.srs_map
    mistakes = st.session_state.mistakes_list

    # åˆ†é¡
    due_items = []
    new_items = []

    # æª¢æŸ¥å¥å­
    for item in st.session_state.sentence_data:
        key = item['sentence']
        if key in srs_map:
            if srs_map[key]['next_review'] <= today_str:
                due_items.append(item)
        elif item['start_date'] <= today_str:
            new_items.append(item)

    # æª¢æŸ¥å–®å­—
    for item in st.session_state.vocab_data:
        key = item['kanji']
        if key in srs_map:
            if srs_map[key]['next_review'] <= today_str:
                due_items.append(item)
        elif item['start_date'] <= today_str:
            new_items.append(item)

    # å„ªå…ˆç´š
    q_item = None
    priority_msg = ""

    if due_items:
        q_item = random.choice(due_items)
        priority_msg = "ğŸ”¥ ä»Šæ—¥åˆ°æœŸ (SRS)"
    elif mistakes and random.random() < 0.7:
        target_key = random.choice(mistakes)
        q_item = next((i for i in st.session_state.sentence_data if i['sentence'] == target_key), None)
        if not q_item:
            q_item = next((i for i in st.session_state.vocab_data if i['kanji'] == target_key), None)
        priority_msg = "ğŸ’€ éŒ¯é¡Œè¤‡ç¿’ (Weak)"
    elif new_items:
        q_item = random.choice(new_items)
        priority_msg = "âœ¨ æ–°é¡Œç›®"
    else:
        all_pool = st.session_state.sentence_data + st.session_state.vocab_data
        if all_pool:
            q_item = random.choice(all_pool)
            priority_msg = "ğŸ² éš¨æ©Ÿç·´ç¿’"
        else:
            st.error("Google Sheets æ²’æœ‰æœ‰æ•ˆè³‡æ–™ï¼")
            return

    st.session_state.priority_msg = priority_msg
    
    # æ±ºå®šæ¨¡å¼
    if q_item['type'] == 'sentence':
        available_modes = [1, 2, 3, 5, 6, 9]
        if q_item['group'] in st.session_state.group_map and len(st.session_state.group_map[q_item['group']]) >= 2:
            available_modes.append(4)
        mode = random.choice(available_modes)
    else:
        mode = random.choice([7, 8, 10])

    setup_question(q_item, mode)

def setup_question(q_item, mode):
    st.session_state.current_q = q_item
    st.session_state.mode = mode
    
    is_vocab_mode = mode in [7, 8, 10]
    
    # Audio
    if mode in [3, 5, 8, 9, 10]:
        text_to_speak = q_item['kanji'] if is_vocab_mode else q_item['sentence']
        st.session_state.audio_data = get_audio_bytes(text_to_speak)
        
    # Options Generation (ç•¥ç‚ºç°¡åŒ–ï¼Œèˆ‡åŸé‚è¼¯ç›¸åŒ)
    if mode in [1, 2, 3, 4, 8]:
        pool = []
        correct = ""
        if mode in [1, 3]: 
            correct = q_item['translation']
            pool = st.session_state.trans_pool
        elif mode == 2:
            correct = q_item['sentence']
            pool = [i['sentence'] for i in st.session_state.sentence_data]
        elif mode == 8:
            correct = q_item['meaning']
            pool = st.session_state.meaning_pool
        elif mode == 4:
            # Group Logic
            gid = q_item['group']
            correct = random.choice([s for s in st.session_state.group_map[gid] if s != q_item['sentence']])
            other_gids = [g for g in st.session_state.group_map if g != gid]
            pool = []
            for og in other_gids: pool.extend(st.session_state.group_map[og])
        
        # Safe sample
        distractors = random.sample([x for x in pool if x != correct], min(3, len(pool)))
        final_opts = distractors + [correct]
        random.shuffle(final_opts)
        st.session_state.options = final_opts

    # Parsing setup
    if mode == 6:
        raw_parts = q_item['parsing'].copy() if q_item['parsing'] else [q_item['sentence']]
        indexed_parts = [{'id': i, 'text': t} for i, t in enumerate(raw_parts)]
        random.shuffle(indexed_parts)
        st.session_state.shuffled_parsing = indexed_parts

# --- 7. ä½œç­”æª¢æŸ¥èˆ‡å›å¯« ---

def check_answer(user_input):
    if st.session_state.feedback is not None: return
    item = st.session_state.current_q
    mode = st.session_state.mode
    
    # æ¨™æº–åŒ–ç­”æ¡ˆ
    user_clean = str(user_input).replace(" ", "").replace("ã€€", "")
    target = item['translation'] if mode in [1,3] else (item['meaning'] if mode == 8 else (item['reading'] if mode == 7 else item['sentence'] if item['type']=='sentence' else item['kanji']))
    
    # æ¯”å°
    is_correct = False
    if mode == 4: is_correct = (user_input in st.session_state.group_map.get(item['group'], []))
    elif mode in [1, 2, 3, 8]: is_correct = (user_clean == str(target).replace(" ", ""))
    else:
        def clean_chars(t): return re.sub(r'[ã€‚ã€ï¼Ÿï¼\?!\sã€€]', '', str(t))
        is_correct = (get_hiragana(clean_chars(user_input)) == get_hiragana(clean_chars(target)))

    # === æ›´æ–° Google Sheets ===
    key = item['sentence'] if item['type'] == 'sentence' else item['kanji']
    row_idx = item['row_idx']
    
    # å‘¼å«æ›´æ–°å‡½å¼
    new_interval, next_review_date = update_srs_status_sheet(key, is_correct, row_idx)

    # ç”¢ç”Ÿå›é¥‹è¨Šæ¯
    msg_type = "success" if is_correct else "error"
    msg_header = "ğŸ‰ æ­£è§£ï¼" if is_correct else f"âŒ æ®‹å¿µ... æ­£è§£: {target}"
    
    detail_html = f"""
    <br>ğŸ“… ä¸‹æ¬¡è¤‡ç¿’: {next_review_date} (é–“éš”: {new_interval} å¤©)
    <br>ğŸ’¾ å·²åŒæ­¥è‡³ Google Sheets
    """
    
    st.session_state.feedback = {"type": msg_type, "msg": msg_header + detail_html}
    
    # è‹¥ç­”éŒ¯é¡¯ç¤ºè©³ç´°æ¯”è¼ƒ
    if not is_correct and mode not in [1,2,3,4,8]:
        st.session_state.feedback["msg"] += f"<br>å·®ç•°: {generate_diff(str(user_input), str(target))}"

    # æ’­æ”¾æ­£ç¢ºèªéŸ³
    speak_text = item['kanji'] if (mode in [7,8,10]) else item['sentence']
    st.session_state.audio_data = get_audio_bytes(speak_text)

# --- Mode 6 è¼”åŠ© ---
def select_block(idx): st.session_state.selected_indices.append(idx)
def deselect_block(idx): st.session_state.selected_indices.remove(idx)
def submit_parsing():
    lookup = {item['id']: item['text'] for item in st.session_state.shuffled_parsing}
    user_sentence = "".join([lookup[i] for i in st.session_state.selected_indices])
    check_answer(user_sentence)

# --- 8. UI é¡¯ç¤º ---

st.set_page_config(page_title="é›²ç«¯æ—¥èªç‰¹è¨“", page_icon="ğŸ‡¯ğŸ‡µ")

with st.sidebar:
    st.title("â˜ï¸ é›²ç«¯åŒæ­¥ä¸­")
    srs_map = st.session_state.get('srs_map', {})
    mistakes = st.session_state.get('mistakes_list', [])
    today_str = datetime.now().strftime("%Y-%m-%d")
    
    due_count = sum(1 for v in srs_map.values() if v['next_review'] <= today_str)
    st.metric("ğŸ”¥ ä»Šæ—¥åˆ°æœŸ", f"{due_count} é¡Œ")
    st.metric("ğŸ’€ éŒ¯é¡Œæœ¬ (Weak)", f"{len(mistakes)} é¡Œ")
    
    if st.button("ğŸ”„ å¼·åˆ¶é‡æ•´è³‡æ–™"):
        st.cache_data.clear()
        del st.session_state.initialized
        st.rerun()

st.title("ğŸ‡¯ğŸ‡µ æ—¥æœ¬èªæ™ºæ…§ç‰¹è¨“ (G-Sheets Ver.)")

if not st.session_state.get('initialized'):
    st.stop()

if st.session_state.current_q is None:
    pick_new_question()

q = st.session_state.current_q
mode = st.session_state.mode

st.info(f"{st.session_state.get('priority_msg')} | Mode {mode}")

# é¡¯ç¤ºé¡Œç›®å€ (ä¾ç…§æ¨¡å¼)
col1, col2 = st.columns([1, 4])
with col2:
    if mode == 1: st.markdown(f"### {q['sentence']}")
    elif mode == 2: st.markdown(f"### {q['translation']}")
    elif mode == 3: 
        st.write("è«‹è½éŸ³æª”ï¼š")
        if st.session_state.audio_data: st.audio(st.session_state.audio_data, format='audio/mpeg')
    elif mode == 4: 
        st.subheader(f"é¡Œç›®: {q['sentence']}")
        st.write("ğŸ‘‰ è«‹é¸å‡ºæ„æ€æœ€ç›¸è¿‘ï¼ˆåŒç¾¤çµ„ï¼‰çš„å¥å­")
    elif mode == 5: 
        st.write("è«‹è½éŸ³æª”ä¸¦å¯«ä¸‹ä¾†ï¼š")
        if st.session_state.audio_data: st.audio(st.session_state.audio_data, format='audio/mpeg')
    elif mode == 6: 
        st.markdown(f"### {q['translation']}")
        st.write("è«‹é‡çµ„å¥å­ï¼š")
    elif mode == 7: 
        st.markdown(f"### {q['kanji']}")
        st.caption(f"æ„æ€: {q['meaning']}")
    elif mode == 8: 
        st.write("è«‹è½å–®å­—ï¼š")
        if st.session_state.audio_data: st.audio(st.session_state.audio_data, format='audio/mpeg')
    elif mode == 9: 
        st.markdown(f"### {q['sentence']}")
        st.caption(f"æ„æ€: {q['translation']}")
    elif mode == 10: st.markdown(f"### {q['kanji']}")

st.divider()

has_answered = st.session_state.feedback is not None

# ä½œç­”å€
if mode in [1, 2, 3, 4, 8]: # é¸æ“‡é¡Œ
    c1, c2 = st.columns(2)
    for i, opt in enumerate(st.session_state.options):
        (c1 if i%2==0 else c2).button(opt, key=f"opt_{i}", on_click=check_answer, args=(opt,), disabled=has_answered, use_container_width=True)

elif mode in [9, 10]: # å£èªª
    if not has_answered:
        col_rec, col_msg = st.columns([1, 3])
        with col_rec:
            audio_blob = mic_recorder(start_prompt="ğŸ™ï¸ éŒ²éŸ³", stop_prompt="â¹ï¸ åœæ­¢", key='mic', format="wav")
        with col_msg:
            if audio_blob:
                res = transcribe_audio_bytes(audio_blob['bytes'])
                st.write(f"ğŸ‘‚: {res}")
                check_answer(res)
                st.rerun()
        if st.button("ğŸ˜¶ Skip"): 
            pick_new_question()
            st.rerun()

elif mode == 6: # é‡çµ„
    # (çœç•¥éƒ¨åˆ†é‡è¤‡ä»£ç¢¼ï¼Œé‚è¼¯åŒåŸç‰ˆï¼Œåªéœ€ç¢ºä¿ selected_indices é‹ä½œæ­£å¸¸)
    # é¡¯ç¤ºå·²é¸
    with st.container(border=True):
        ids = st.session_state.selected_indices
        if not ids: st.write("*(é»æ“Šä¸‹æ–¹å­—å¡)*")
        else:
            cols = st.columns(6)
            lookup = {item['id']: item['text'] for item in st.session_state.shuffled_parsing}
            for i, idx in enumerate(ids):
                cols[i%6].button(lookup[idx], key=f"sel_{idx}", on_click=deselect_block, args=(idx,), disabled=has_answered)
    
    st.write("â¬‡ï¸ å¾…é¸å€")
    avail = [b for b in st.session_state.shuffled_parsing if b['id'] not in ids]
    if avail:
        cols = st.columns(6)
        for i, b in enumerate(avail):
            cols[i%6].button(b['text'], key=f"avail_{b['id']}", on_click=select_block, args=(b['id'],), disabled=has_answered)
    
    if st.button("ğŸš€ é€å‡º", type="primary", disabled=(has_answered or not ids)):
        submit_parsing()
        st.rerun()

else: # æ‰“å­—
    ph = "è«‹è¼¸å…¥å¹³å‡å..." if mode == 7 else "è«‹è¼¸å…¥æ—¥æ–‡..."
    with st.form("ans_form", clear_on_submit=True):
        val = st.text_input("Answer:", placeholder=ph, disabled=has_answered)
        if st.form_submit_button("é€å‡º"):
            check_answer(val)
            st.rerun()

# å›é¥‹å€
# --- å›é¥‹å€ (ä¿®æ”¹ç‰ˆ) ---
if st.session_state.feedback:
    fb = st.session_state.feedback
    
    # 1. é¡¯ç¤ºç­”é¡Œçµæœ (ç¶ è‰²/ç´…è‰²æ©«å¹…)
    if fb['type'] == 'success': 
        st.success(fb['msg'], icon="âœ…")
    else: 
        st.error(fb['msg'], icon="âŒ")
    
    # 2. é¡¯ç¤ºå®Œæ•´è©³è§£ (æ—¥æ–‡ + ä¸­æ–‡ + éŸ³æª”)
    with st.container(border=True):
        st.caption("ğŸ“– é¡Œç›®è©³è§£")
        
        q_item = st.session_state.current_q
        
        # æ ¹æ“šé¡Œç›®é¡å‹é¡¯ç¤ºä¸åŒè³‡è¨Š
        col_text, col_audio = st.columns([3, 1])
        
        with col_text:
            if q_item['type'] == 'sentence':
                st.markdown(f"**ğŸ‡¯ğŸ‡µ æ—¥æ–‡ï¼š**\n### {q_item['sentence']}")
                st.markdown(f"**ğŸ‡¹ğŸ‡¼ ä¸­æ–‡ï¼š** {q_item['translation']}")
                # å¦‚æœæœ‰ parsing è³‡æ–™ä¹Ÿå¯ä»¥é¡¯ç¤ºï¼Œæ²’æœ‰å‰‡ç•¥é
                if q_item.get('parsing'):
                    st.caption(f"çµæ§‹: {' | '.join(q_item['parsing'])}")
            else:
                # å–®å­—é¡Œå‹
                st.markdown(f"**ğŸ‡¯ğŸ‡µ å–®å­—ï¼š**\n### {q_item['kanji']}")
                st.markdown(f"**ğŸ—£ï¸ è®€éŸ³ï¼š** {q_item['reading']}")
                st.markdown(f"**ğŸ‡¹ğŸ‡¼ æ„æ€ï¼š** {q_item['meaning']}")

        with col_audio:
            if st.session_state.audio_data:
                st.write("ğŸ”Š ç™¼éŸ³")
                st.audio(st.session_state.audio_data, format='audio/mpeg')

    # 3. ä¸‹ä¸€é¡ŒæŒ‰éˆ•
    st.button("ğŸ‘‰ ä¸‹ä¸€é¡Œ", on_click=pick_new_question, type="primary", use_container_width=True)